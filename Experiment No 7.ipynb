{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4eea62c-be6a-45e6-9b69-99cbf7524c6f",
   "metadata": {},
   "source": [
    "![](./lab%20header%20image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66a82e-3c64-4e56-8d7c-b15835e618a7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h3>Experiment No. 07</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c407c38-a93b-428d-ad91-6865b43970f1",
   "metadata": {},
   "source": [
    "<img src=\"./Student%20Information.png\" style=\"width: 100%;\" alt=\"Student Information\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445eedca-8bc9-493b-bfbd-681db5fbb355",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #ccc; padding: 8px; background-color: #f0f0f0; text-align: center;\">\n",
    "    <strong>AIM</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a2524-23ae-4df1-af53-9c834d2f54f4",
   "metadata": {},
   "source": [
    "**Study of Python Features in Natural Language Processing (NLP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f1b94-260f-414c-8c1b-0e1b71b99e04",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #ccc; padding: 8px; background-color: #f0f0f0; text-align: center;\">\n",
    "    <strong>Theory/Procedure/Algorithm</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d072d40-3d52-4640-bdb1-b3e185f63f28",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) is a branch of artificial intelligence (AI) focused on enabling machines to interpret, understand, and generate human language. NLP tasks can range from simple operations like tokenization and part-of-speech tagging to complex tasks such as machine translation, summarization, and question answering. Python has become the dominant language for NLP due to its rich ecosystem of libraries like `nltk`, `spaCy`, `gensim`, `TextBlob`, and `transformers`.\n",
    "\n",
    "##### Key Python Features for NLP:\n",
    "1. **Tokenization**: Breaking down text into smaller units (words, sentences).\n",
    "2. **Text Cleaning**: Removing stop words, punctuation, and performing lemmatization or stemming.\n",
    "3. **Vectorization**: Representing text numerically, often using techniques like Bag-of-Words (BoW) or Term Frequency-Inverse Document Frequency (TF-IDF).\n",
    "4. **Part-of-Speech (POS) Tagging**: Assigning tags like noun, verb, adjective to each token.\n",
    "5. **Named Entity Recognition (NER)**: Identifying entities like names, places, dates from text.\n",
    "6. **Sentiment Analysis**: Classifying text based on its sentiment (positive, negative, neutral).\n",
    "7. **Word Embeddings**: Dense vector representation of words, enabling better semantic understanding.\n",
    "8. **Language Modeling**: Predicting the next word in a sequence, used in tasks like text generation.\n",
    "\n",
    "##### Implementation\n",
    "To demonstrate the above features, a Python implementation using libraries such as `nltk`, `spaCy`, and `transformers` was carried out. Each library was chosen based on its strength in specific NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d02ad-e953-4c93-b201-b4f14df93eaa",
   "metadata": {},
   "source": [
    "**1. Tokenization using NLTK**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf85d8d-36e8-4fb2-8318-9c583b0876f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'is', 'widely', 'used', 'in', 'NLP', 'due', 'to', 'its', 'vast', 'library', 'support', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kamran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Python is widely used in NLP due to its vast library support.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6777f52-7174-4dd6-b96c-2f5b4fbf6c86",
   "metadata": {},
   "source": [
    "*Explanation*: `nltk.tokenize` breaks the sentence into individual words or tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccad6e2-5535-4bff-9609-eaa218afbeca",
   "metadata": {},
   "source": [
    "**2. Text Cleaning and Lemmatization with spaCy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08bc0554-d365-4251-9f11-f02657e42097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'fast', 'goal']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(\"Running faster is my goal\")\n",
    "cleaned_tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "print(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4479e62-6d50-4ad4-b09e-4fbbb749fa8e",
   "metadata": {},
   "source": [
    "*Explanation*: Lemmatization converts words into their base form (e.g., \"running\" to \"run\"), while removing stop words like \"is\", \"my\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b9c9a-478e-4d4e-ad3a-2e00644b53de",
   "metadata": {},
   "source": [
    "**3. Vectorization using TF-IDF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716b629c-07b1-4c6c-ae08-b7d66f7da1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.47107781 0.47107781 0.47107781 0.\n",
      "  0.         0.33517574 0.47107781]\n",
      " [0.47107781 0.47107781 0.         0.         0.         0.47107781\n",
      "  0.47107781 0.33517574 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\"Python is great for NLP\", \"Machine learning enhances NLP capabilities\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "print(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29e76eb-a863-426f-a1cc-bdab1d2c8c41",
   "metadata": {},
   "source": [
    "*Explanation*: TF-IDF measures the importance of words in a document relative to a corpus. It’s used for representing text data in numeric form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b4ee3-7072-46ae-aec8-557462a264a1",
   "metadata": {},
   "source": [
    "**4. Named Entity Recognition (NER) using spaCy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2fe3da-bc73-4941-891b-4edb0072873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google ORG\n",
      "Mountain View GPE\n",
      "today DATE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Google, based in Mountain View, announced a new feature today.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9544d651-c7ab-4728-891d-f355e27c100b",
   "metadata": {},
   "source": [
    "*Explanation*: Named entities like \"Google\" and \"Mountain View\" are extracted, categorized as organizations, and places, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f20abde-581a-4c10-a6c7-b65d8abbe25c",
   "metadata": {},
   "source": [
    "**5. Sentiment Analysis using TextBlob:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb8076e-74c8-4de4-993f-0d0ec79b59b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.35714285714285715)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = \"Python makes NLP simple and intuitive.\"\n",
    "blob = TextBlob(text)\n",
    "print(blob.sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a39dfd-695f-4d5f-b50b-9b36289b40db",
   "metadata": {},
   "source": [
    "*Explanation*: `TextBlob` provides a simple way to perform sentiment analysis, returning polarity (positive/negative) and subjectivity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9c5ea5-0897-416d-b5ac-2c5d8af90d3e",
   "metadata": {},
   "source": [
    "**6. Word Embeddings using Gensim’s Word2Vec:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f5e707-588f-494d-8a2a-486743a425b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.1681199e-03 -4.4430327e-03  8.9854337e-03  8.2536647e-03\n",
      " -4.4352221e-03  3.0310510e-04  4.2744912e-03 -3.9263200e-03\n",
      " -5.5599655e-03 -6.5123225e-03 -6.7073823e-04 -2.9592158e-04\n",
      "  4.4630850e-03 -2.4740540e-03 -1.7260908e-04  2.4618758e-03\n",
      "  4.8675989e-03 -3.0808449e-05 -6.3394094e-03 -9.2608072e-03\n",
      "  2.6657581e-05  6.6618943e-03  1.4660227e-03 -8.9665223e-03\n",
      " -7.9386048e-03  6.5519023e-03 -3.7856805e-03  6.2549924e-03\n",
      " -6.6810320e-03  8.4796622e-03 -6.5163244e-03  3.2880199e-03\n",
      " -1.0569858e-03 -6.7875278e-03 -3.2875966e-03 -1.1614120e-03\n",
      " -5.4709399e-03 -1.2113475e-03 -7.5633135e-03  2.6466595e-03\n",
      "  9.0701487e-03 -2.3772502e-03 -9.7651005e-04  3.5135616e-03\n",
      "  8.6650876e-03 -5.9218528e-03 -6.8875779e-03 -2.9329848e-03\n",
      "  9.1476962e-03  8.6626766e-04 -8.6784009e-03 -1.4469790e-03\n",
      "  9.4794659e-03 -7.5494875e-03 -5.3580985e-03  9.3165627e-03\n",
      " -8.9737261e-03  3.8259076e-03  6.6544057e-04  6.6607012e-03\n",
      "  8.3127534e-03 -2.8507852e-03 -3.9923131e-03  8.8979173e-03\n",
      "  2.0896459e-03  6.2489416e-03 -9.4457148e-03  9.5901238e-03\n",
      " -1.3483083e-03 -6.0521150e-03  2.9925345e-03 -4.5661093e-04\n",
      "  4.7064926e-03 -2.2830211e-03 -4.1378425e-03  2.2778988e-03\n",
      "  8.3543835e-03 -4.9956059e-03  2.6686788e-03 -7.9905549e-03\n",
      " -6.7733466e-03 -4.6766878e-04 -8.7677278e-03  2.7894378e-03\n",
      "  1.5985954e-03 -2.3196924e-03  5.0037908e-03  9.7487867e-03\n",
      "  8.4542679e-03 -1.8802249e-03  2.0581519e-03 -4.0036892e-03\n",
      " -8.2414057e-03  6.2779556e-03 -1.9491815e-03 -6.6620467e-04\n",
      " -1.7713320e-03 -4.5356657e-03  4.0617096e-03 -4.2701806e-03]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [[\"python\", \"is\", \"great\", \"for\", \"nlp\"], [\"machine\", \"learning\", \"is\", \"useful\"]]\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "vector = model.wv['python']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc58e80-d002-4bde-a5a5-754a9f5ffe06",
   "metadata": {},
   "source": [
    "*Explanation*: Word2Vec represents words as vectors in a continuous space, capturing semantic relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7005f-5d55-4185-b516-af65e0f20bb0",
   "metadata": {},
   "source": [
    "**7. Language Modeling using Hugging Face Transformers (GPT-2):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7964c4-c339-4ab0-b765-c96150dd4c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kamran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kamran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Kamran\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Natural Language Processing with Python\\n\\nPython provides a fairly easy way to program in Python. Python will simply run a list of numbers and return data. If a list of integers is given, in your case, Python will do this to it, or'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "result = generator(\"Natural Language Processing with Python\", max_length=50, num_return_sequences=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926e1b5-26f9-4919-b18f-702a5469a015",
   "metadata": {},
   "source": [
    "*Explanation*: Hugging Face’s `transformers` library is used for generating text using a pre-trained GPT-2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab992f17-f9a0-477d-a948-d1307e838670",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #ccc; padding: 8px; background-color: #f0f0f0; text-align: center;\">\n",
    "    <strong>CONCLUSION</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2814c1-f8f9-4094-872a-150db4e9b724",
   "metadata": {},
   "source": [
    "This study demonstrates Python’s flexibility and robustness in performing diverse NLP tasks, thanks to its extensive libraries and easy-to-use APIs. Key takeaways include:\n",
    "\n",
    "- **Text Preprocessing**: Tokenization and text cleaning form the foundation for more advanced NLP tasks, with libraries like `nltk` and `spaCy` offering high efficiency.\n",
    "- **Feature Extraction**: Techniques like TF-IDF and Word2Vec are vital for converting text data into a format that machine learning models can understand.\n",
    "- **Sentiment Analysis and NER**: Python libraries make it simple to extract useful information and perform sentiment-based classification.\n",
    "- **Language Models**: Pre-trained models like GPT-2 allow for advanced language generation, showing the power of transformer-based models.\n",
    "\n",
    "The study concludes that Python, due to its rich ecosystem of NLP libraries, offers a powerful platform for both academic research and real-world applications in Natural Language Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c7e0f-bfc4-4f83-b8cd-09825d2bb4ba",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #ccc; padding: 8px; background-color: #f0f0f0; text-align: center;\">\n",
    "    <strong>ASSESSMENT</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e759ecfd-0552-401d-ad9c-09e6f26a8ed3",
   "metadata": {},
   "source": [
    "<img src=\"./marks_distribution.png\" style=\"width: 100%;\" alt=\"marks_distribution\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
