{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./lab%20header%20image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h3>Assignment No. 01</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Student%20Information.png\" style=\"width: 100%;\" alt=\"Student Information\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #ccc; padding: 8px; background-color: #f0f0f0; text-align: start;\">\n",
    "    <strong>Q. Write note on word normalization and stemming. Explain case folding with suitable example</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text preprocessing** is a crucial step in natural language processing (NLP) that prepares raw text data for analysis. It typically involves several key steps: tokenization (breaking text into individual words or phrases), removing punctuation and special characters, converting text to lowercase, eliminating stop words (common words like \"the\" or \"and\" that add little meaning), and applying stemming or lemmatization (reducing words to their root form). These processes help standardize the text, reduce noise, and create a more uniform dataset for analysis. The goal is to transform unstructured text into a format that's easier for machines to process, allowing for more accurate and efficient analysis in NLP tasks such as sentiment analysis, topic modeling, or text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Tokenization**: \n",
    "- **Definition**: Tokenization is the process of breaking down text into smaller units called tokens. These tokens can be words, phrases, or even characters, depending on the level of granularity needed.\n",
    "- **Example**: For the sentence \"I love programming!\", tokenization would yield `[\"I\", \"love\", \"programming\", \"!\"]`.\n",
    "- **Purpose**: Tokenization helps in analyzing the structure of the text and is a foundational step in NLP, enabling further processing like filtration, stemming, and model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentences: ['\\nNatural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through language.', 'It involves the analysis, understanding, and generation of the languages that humans use naturally.', 'NLP has various applications, including sentiment analysis, \\nmachine translation, and speech recognition.']\n",
      "\n",
      "Tokens: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'language', '.', 'It', 'involves', 'the', 'analysis', ',', 'understanding', ',', 'and', 'generation', 'of', 'the', 'languages', 'that', 'humans', 'use', 'naturally', '.', 'NLP', 'has', 'various', 'applications', ',', 'including', 'sentiment', 'analysis', ',', 'machine', 'translation', ',', 'and', 'speech', 'recognition', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through language. \n",
    "It involves the analysis, understanding, and generation of the languages that humans use naturally. NLP has various applications, including sentiment analysis, \n",
    "machine translation, and speech recognition.\n",
    "\"\"\"\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "print(\"\\nSentences:\", sentences)\n",
    "print(\"\\nTokens:\", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2. Filtration**\n",
    "   - **Definition**: Filtration involves removing unnecessary elements from the text, such as punctuation marks, special characters, numbers, or even specific words that do not contribute meaningfully to the analysis.\n",
    "   - **Example**: In the sentence \"I have 2 dogs.\", filtration might remove the number \"2\" and punctuation, resulting in \"I have dogs\".\n",
    "   - **Purpose**: Filtration cleans the text, making it easier to process and reducing noise in the data, which improves the performance of NLP models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Tokens: ['Natural', 'language', 'processing', 'NLP', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'language', 'It', 'involves', 'the', 'analysis', 'understanding', 'and', 'generation', 'of', 'the', 'languages', 'that', 'humans', 'use', 'naturally', 'NLP', 'has', 'various', 'applications', 'including', 'sentiment', 'analysis', 'machine', 'translation', 'and', 'speech', 'recognition']\n"
     ]
    }
   ],
   "source": [
    "# Filtration (Removing punctuation, special characters, and numbers)\n",
    "\n",
    "filtered_tokens = [word for word in tokens if word.isalpha()]\n",
    "print(\"\\nFiltered Tokens:\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3. Script Validation**\n",
    "   - **Definition**: Script validation checks whether the text is in the expected script (like Latin, Cyrillic, etc.) or language. This step ensures that the text is valid and relevant to the context of the analysis.\n",
    "   - **Example**: If analyzing English text, script validation might remove text written in other scripts, like \"こんにちは\" (Japanese).\n",
    "   - **Purpose**: Script validation helps in maintaining consistency in the data, ensuring that only relevant text is processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "English Script Tokens: ['Natural', 'language', 'processing', 'NLP', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'language', 'It', 'involves', 'the', 'analysis', 'understanding', 'and', 'generation', 'of', 'the', 'languages', 'that', 'humans', 'use', 'naturally', 'NLP', 'has', 'various', 'applications', 'including', 'sentiment', 'analysis', 'machine', 'translation', 'and', 'speech', 'recognition']\n",
      "\n",
      "Latin Script Tokens: ['Natural', 'language', 'processing', 'NLP', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'language', 'It', 'involves', 'the', 'analysis', 'understanding', 'and', 'generation', 'of', 'the', 'languages', 'that', 'humans', 'use', 'naturally', 'NLP', 'has', 'various', 'applications', 'including', 'sentiment', 'analysis', 'machine', 'translation', 'and', 'speech', 'recognition']\n"
     ]
    }
   ],
   "source": [
    "# Function to validate if a token is in the English script (ASCII characters)\n",
    "def is_english_script(word):\n",
    "    return all(ord(char) < 128 for char in word)\n",
    "\n",
    "# Function to validate if a token is in the Latin script\n",
    "def is_latin_script(word):\n",
    "    try:\n",
    "        return all('LATIN' in unicodedata.name(char) for char in word)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# a: Script Validation for English (ASCII characters only)\n",
    "english_tokens = [word for word in filtered_tokens if is_english_script(word)]\n",
    "print(\"\\nEnglish Script Tokens:\", english_tokens)\n",
    "\n",
    "# b: Script Validation for Latin Script\n",
    "latin_tokens = [word for word in filtered_tokens if is_latin_script(word)]\n",
    "print(\"\\nLatin Script Tokens:\", latin_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4. Stop Word Removal**\n",
    "   - **Definition**: Stop words are common words in a language (like \"and,\" \"the,\" \"is\") that do not add significant meaning and are often removed from the text to focus on more informative words.\n",
    "   - **Example**: For the sentence \"The cat is on the mat,\" stop word removal would yield `[\"cat\", \"mat\"]`.\n",
    "   - **Purpose**: Removing stop words reduces the dimensionality of the data, focusing on the most relevant information for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokens without Stop Words: ['natural', 'language', 'processing', 'nlp', 'field', 'artificial', 'intelligence', 'focuses', 'interaction', 'computers', 'humans', 'language', 'involves', 'analysis', 'understanding', 'generation', 'languages', 'humans', 'use', 'naturally', 'nlp', 'various', 'applications', 'including', 'sentiment', 'analysis', 'machine', 'translation', 'speech', 'recognition']\n"
     ]
    }
   ],
   "source": [
    "# Stop Word Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens_without_stopwords = [word.lower() for word in english_tokens if word.lower() not in stop_words]\n",
    "print(\"\\nTokens without Stop Words:\", tokens_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5. Stemming**\n",
    "   - **Definition**: Stemming reduces words to their root form by removing suffixes or prefixes. For instance, \"running\" becomes \"run\" and \"played\" becomes \"play\".\n",
    "   - **Example**: \"Playing\", \"played\", and \"plays\" would all be reduced to \"play\".\n",
    "   - **Purpose**: Stemming simplifies the text by consolidating different forms of a word into a single term, making it easier for models to learn patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemmed Tokens: ['natur', 'languag', 'process', 'nlp', 'field', 'artifici', 'intellig', 'focus', 'interact', 'comput', 'human', 'languag', 'involv', 'analysi', 'understand', 'gener', 'languag', 'human', 'use', 'natur', 'nlp', 'variou', 'applic', 'includ', 'sentiment', 'analysi', 'machin', 'translat', 'speech', 'recognit']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in tokens_without_stopwords]\n",
    "print(\"\\nStemmed Tokens:\", stemmed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing in NLP prepares raw text for analysis through steps like tokenization, cleaning, stop word removal, and stemming/lemmatization. While essential for simplifying text and improving model performance, it has limitations such as creating meaningless stems or losing context. Understanding these trade-offs is crucial for effective text processing and insight extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float: right; border: 1px solid black; display: inline-block; padding: 10px; text-align: center\">\n",
    "    <br>\n",
    "    <br>\n",
    "    <span style=\"font-weight: bold;\">Signature of Lab Incharge</span>\n",
    "    <br>\n",
    "    <span>(Prof. Rupali Sharma)</span> \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
